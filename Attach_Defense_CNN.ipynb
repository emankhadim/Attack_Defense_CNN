{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0lIDeXURwXWm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import foolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a simple CNN model for image classification"
      ],
      "metadata": {
        "id": "r5RMLfE5x0qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(14 * 14 * 32, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sbdd-d9JxKrN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample dataset (MNIST)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
      ],
      "metadata": {
        "id": "D2MfmZwrykR9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yh5kmPGy0EE",
        "outputId": "40e9c0b6-9a88-45fa-864a-2a3dbbe0939e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 119982774.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 19534864.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 51367708.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 18265128.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "6MIVvuFYzLFI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()"
      ],
      "metadata": {
        "id": "x1FPkww2zLhE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-Entropy Loss.**\n",
        "\n",
        "Suitability for Classification:\n",
        "Cross-entropy loss is commonly used for classification tasks, especially when dealing with multiple classes. It measures the dissimilarity between the predicted class probabilities and the true distribution of class labels."
      ],
      "metadata": {
        "id": "0snqx_uozqqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9lR0VgVNzLvh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adam Optimizer**\n",
        "\n",
        "Adaptive Learning Rate:\n",
        "Adam is an adaptive optimization algorithm that adjusts the learning rate for each parameter individually. It helps in speeding up convergence and dealing with different magnitudes of gradients for different parameters."
      ],
      "metadata": {
        "id": "ymIuDuo_zy-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "JRElUnGgzL39"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the model"
      ],
      "metadata": {
        "id": "Cr5Inuf_0Dvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for inputs, labels in trainLoader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()image, label = trainSet[0]\n",
        "image = image.numpy()\n",
        "\n",
        "adversarial_image_tensor = torch.from_numpy(image).float()\n",
        "fmodel = foolbox.PyTorchModel(model, bounds=(0, 1))"
      ],
      "metadata": {
        "id": "EfLP87ig0JDE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_value = 0.1\n",
        "attack =  torchattacks.FGSM(model, eps=8/255)"
      ],
      "metadata": {
        "id": "j8BWsena_bDM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor(labels).clone().detach().requires_grad_(True)\n",
        "adversarial_image = attack( adversarial_image_tensor, labels)"
      ],
      "metadata": {
        "id": "tMhVDOpZFcae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adversarial Defense **"
      ],
      "metadata": {
        "id": "Q-BGpnAZ4TSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def adversarial_training(model, trainLoader, criterion, optimizer, epsilon=0.01, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in trainLoader:\n",
        "            # Create adversarial examples\n",
        "            fmodel = foolbox.PyTorchModel(model, bounds=(0, 1))\n",
        "            attack = foolbox.attacks.FGSM(fmodel)\n",
        "            inputs_adv = torch.tensor([attack(image.numpy(), label) for image, label in zip(inputs, labels)])\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            outputs_adv = model(inputs_adv)\n",
        "\n",
        "            # Calculate losses\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_adv = criterion(outputs_adv, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            (loss + loss_adv).backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "inxe_QGqHFlq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_defense = SimpleCNN()\n",
        "\n",
        "criterion_defense = nn.CrossEntropyLoss()\n",
        "optimizer_defense = optim.Adam(model_defense.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model with adversarial training\n",
        "adversarial_training( model= model_defense,trainLoader=trainLoader, criterion=criterion_defense,  num_epochs=10)\n",
        "\n",
        "# Evaluate the model on the adversarial example\n",
        "inputs_adv_tensor = torch.tensor(adversarial_image)\n",
        "outputs_defense = model_defense(inputs_adv_tensor.unsqueeze(0))\n",
        "\n",
        "# Convert logits to probabilities and get the predicted class\n",
        "probabilities = nn.Softmax(dim=1)(outputs_defense)\n",
        "_, predicted_class = torch.max(probabilities, 1)\n",
        "\n",
        "print(f'Predicted class after adversarial training: {predicted_class.item()}')"
      ],
      "metadata": {
        "id": "G2XuDQLz2RXY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adversarial Attack Evaluation:**\n",
        "\n",
        "After generating an adversarial example, i evaluate the model's performance on both the original and adversarial examples. The key metrics to check are:"
      ],
      "metadata": {
        "id": "gB5A8TKz3vzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the original example\n",
        "outputs_original = model(torch.tensor(image).unsqueeze(0))\n",
        "_, predicted_original = torch.max(F.softmax(outputs_original, dim=1), 1)\n",
        "print(f'Predicted class on original example: {predicted_original.item()}')\n",
        "\n",
        "# Evaluate the model on the adversarial example\n",
        "outputs_adversarial = model(torch.tensor(adversarial_image).unsqueeze(0))\n",
        "_, predicted_adversarial = torch.max(F.softmax(outputs_adversarial, dim=1), 1)\n",
        "print(f'Predicted class on adversarial example: {predicted_adversarial.item()}')\n",
        "\n"
      ],
      "metadata": {
        "id": "1VNjQcOr13qu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adversarial Defense Evaluation:**\n",
        "\n",
        "\n",
        "After training the model with adversarial training, i  evaluate its performance on both the original and adversarial examples:"
      ],
      "metadata": {
        "id": "du4T3D4D311F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the defense model on the original example\n",
        "outputs_defense_original = model_defense(torch.tensor(image).unsqueeze(0))\n",
        "_, predicted_defense_original = torch.max(F.softmax(outputs_defense_original, dim=1), 1)\n",
        "print(f'Predicted class on original example after adversarial training: {predicted_defense_original.item()}')\n",
        "\n",
        "# Evaluate the defense model on the adversarial example\n",
        "outputs_defense_adversarial = model_defense(torch.tensor(adversarial_image).unsqueeze(0))\n",
        "_, predicted_defense_adversarial = torch.max(F.softmax(outputs_defense_adversarial, dim=1), 1)\n",
        "print(f'Predicted class on adversarial example after adversarial training: {predicted_defense_adversarial.item()}')"
      ],
      "metadata": {
        "id": "E9pKgJqv17c2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}